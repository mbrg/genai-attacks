{
    "$id": "$gai-technique/cloud_service_discovery",
    "$schema": "../schema/technique.schema.json",
    "$type": "technique",
    "description": "An adversary may attempt to discover and enumerate LLM and AI services deployed in cloud environments to identify targets for further attacks. Cloud providers offer numerous AI and ML services such as Amazon Bedrock, Azure OpenAI Service, Google Cloud AI Platform, hosted model endpoints, inference APIs, and container-based ML workloads.\n\nAdversaries may use cloud-native tools and APIs such as the Microsoft Graph API, Azure Resource Manager API, AWS CLI, or Google Cloud SDK to enumerate AI resources, model repositories, training jobs, and their access permissions. This reconnaissance helps adversaries understand the AI attack surface and identify vulnerable LLM services for subsequent exploitation, data exfiltration, or supply chain compromise.",
    "external_references": [],
    "framework_references": [
      {
        "framework_id": "AML.T0075",
        "framework_name": "MITRE ATLAS",
        "href": "https://atlas.mitre.org/techniques/AML.T0075"
      }
    ],
    "name": "Cloud Service Discovery",
    "object_references": [
      {
        "$id": "$gai-tactic/discovery",
        "$type": "tactic",
        "description": "Adversaries may use the information gained to shape follow-on behaviors, such as targeting data or credentials from enumerated services or evading identified defenses through Disable or Modify Tools or Disable or Modify Cloud Logs."
      }
    ]
  }