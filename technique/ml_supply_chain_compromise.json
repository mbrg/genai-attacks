{
  "$id": "$gai-technique/ml_supply_chain_compromise",
  "$schema": "../schema/technique.schema.json",
  "$type": "technique",
  "description": "Adversaries may gain initial access to a system by compromising the unique portions of the ML supply chain. This could include hardware, data and its annotations, parts of the ML software stack, or the model itself. In some instances the attacker will need secondary access to fully carry out an attack using compromised components of the supply chain.",
  "external_references": [],
  "framework_references": [
    {
      "framework_id": "AML.T0010",
      "framework_name": "MITRE ATLAS",
      "href": "https://atlas.mitre.org/techniques/AML.T0010"
    }
  ],
  "name": "ML Supply Chain Compromise",
  "object_references": [
    {
      "$id": "$gai-tactic/initial_access",
      "$type": "tactic",
      "description": "Compromising machine learning supply chains to gain unauthorized access or introduce malicious components."
    }
  ]
}
