{
  "$id": "$gai-technique/search_open_ai_vulnerability_analysis",
  "$schema": "../schema/technique.schema.json",
  "$type": "technique",
  "description": "Much like the Search Open Technical Databases, there is often ample research available on the vulnerabilities of common AI models. Once a target has been identified, an adversary will likely try to identify any pre-existing work that has been done for this class of models. This will include not only reading academic papers that may identify the particulars of a successful attack, but also identifying pre-existing implementations of those attacks. The adversary may obtain Adversarial AI Attack Implementations or develop their own Adversarial AI Attacks if necessary.",
  "external_references": [],
  "framework_references": [
    {
      "framework_id": "AML.T0001",
      "framework_name": "MITRE ATLAS",
      "href": "https://atlas.mitre.org/techniques/AML.T0001"
    }
  ],
  "name": "Search Open AI Vulnerability Analysis",
  "object_references": [
    {
      "$id": "$gai-tactic/reconnaissance",
      "$type": "tactic",
      "description": "Gathering available vulnerability analysis materials allows adversaries to understand how and where machine learning is vulnerable, aiding in planning tailored attacks."
    }
  ]
}
